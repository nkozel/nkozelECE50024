{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1--symCSCtlWX7TPPFhm1EJvufROvo6eb","authorship_tag":"ABX9TyOcJp6goieQ3qI1pJ33YqQe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from matplotlib import pyplot as plt\n","import pdb\n","from google.colab.patches import cv2_imshow\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","from os import listdir\n","import csv\n","from PIL import Image\n","import tensorflow as tf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eg9HypL10VMI","executionInfo":{"status":"ok","timestamp":1711956782258,"user_tz":240,"elapsed":11700,"user":{"displayName":"Nicole Kozel","userId":"13795370668639158691"}},"outputId":"4711504e-accd-4b6c-8ec5-07ebf279378e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cwtv2elXPJji","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711253586417,"user_tz":240,"elapsed":579860,"user":{"displayName":"Nicole Kozel","userId":"13795370668639158691"}},"outputId":"669dbe43-aa0d-42a5-e895-1e4e8f10d5a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["4224.jpg\n","3749.jpg\n","6619.jpg\n","4032.jpg\n","596.jpg\n","6220.jpg\n","554.jpg\n","2456.jpg\n","144.jpg\n","385.jpg\n","178.jpg\n","2871.jpg\n","393.jpg\n","3164.jpg\n","1217.jpg\n","3950.jpg\n","1828.jpg\n","6435.jpg\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["1207.jpg\n","1617.jpg\n","1830.jpg\n","3570.jpg\n","6150.jpg\n","6636.jpg\n","5895.jpg\n","746.jpg\n","3868.jpg\n","6535.jpg\n","5954.jpg\n","2949.jpg\n","3128.jpg\n","3869.jpg\n","3110.jpg\n","3306.jpg\n","1934.jpg\n","4497.jpg\n","709.jpg\n","6135.jpg\n","2435.jpg\n","6269.jpg\n","508.jpg\n","11.jpg\n","1645.jpg\n","3091.jpg\n","4113.jpg\n","1254.jpg\n","6275.jpg\n","4884.jpg\n","2173.jpg\n","2368.jpg\n","1104.jpg\n","2425.jpg\n","296.jpg\n","2790.jpg\n","6270.jpg\n","3081.jpg\n","2837.jpg\n","857.jpg\n","5380.jpg\n","4500.jpg\n","6129.jpg\n","107.jpg\n","3737.jpg\n","3093.jpg\n","847.jpg\n","106.jpg\n","6823.jpg\n","400.jpg\n","2099.jpg\n","3423.jpg\n","2339.jpg\n","832.jpg\n","3780.jpg\n","4945.jpg\n","5044.jpg\n","5939.jpg\n","3187.jpg\n","4993.jpg\n","1151.jpg\n","4798.jpg\n","6944.jpg\n","4002.jpg\n","2881.jpg\n","5491.jpg\n","2704.jpg\n","5889.jpg\n","2884.jpg\n","4007.jpg\n","5682.jpg\n","6638.jpg\n"]}],"source":["# Face cropping method from https://datagen.tech/guides/face-recognition/face-detection-with-opencv-2-quick-tutorials/#:~:text=DNN%20Face%20Detector%20is%20a,scales%2C%20poses%2C%20and%20occlusions.\n","# Iterating through images in a folder from https://www.geeksforgeeks.org/how-to-iterate-through-images-in-a-folder-python/\n","# Training/Testing Model from https://www.atmosera.com/blog/facial-recognition-with-cnns/#:~:text=One%20of%20the%20primary%20benchmarks,99%25%20accuracy%20on%20the%20dataset\n","# This code was run on personal machine and the cropped images were copied into subfolders on google drive to avoid issues with folder size and google colab\n","\n","\n","# Load the DNN Face Detector model\n","from cv2 import dnn\n","prototxt = '/content/drive/MyDrive/ECE50024Challenge/deploy.prototxt.txt'\n","caffemodel='/content/drive/MyDrive/ECE50024Challenge/res10_300x300_ssd_iter_140000.caffemodel'\n","face_detector =  cv2.dnn.readNetFromCaffe( prototxt, caffemodel)\n","#face_detector = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\", \"res10_300x300_ssd_iter_140000.caffemodel\")\n","\n","# get the path/directory\n","folder_dir = \"/content/drive/MyDrive/ECE50024Challenge/train_small/train_small/\"\n","for images in os.listdir(folder_dir):\n","    # check if the image ends with jpg\n","    if (images.endswith(\".jpg\")):\n","        #Make images readable\n","        img=Image.open('/content/drive/MyDrive/ECE50024Challenge/train_small/train_small/'+images)\n","        imgCheck = cv2.imread('/content/drive/MyDrive/ECE50024Challenge/train_small/train_small/'+images)\n","        if img.mode != 'RGB' or imgCheck is None:\n","            img = img.convert(mode=\"RGB\", colors=24)\n","            img.save('/content/drive/MyDrive/ECE50024Challenge/train_small_readable/'+images)\n","            img = cv2.imread('/content/drive/MyDrive/ECE50024Challenge/train_small_readable/'+images)\n","        else:\n","            img = cv2.imread('/content/drive/MyDrive/ECE50024Challenge/train_small/train_small/'+images)\n","\n","        # Get the height and width of the input image\n","        (h, w) = img.shape[:2]\n","\n","        # Preprocess the image by resizing it and converting it to a blob\n","        blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n","\n","        # Feed the blob as input to the DNN Face Detector model\n","        face_detector.setInput(blob)\n","        detections = face_detector.forward()\n","\n","        # Loop over the detections and draw a rectangle around each face\n","        confidence = detections[0, 0, 0, 2]\n","\n","        # Filter out weak detections\n","        if confidence > 0.25:\n","            # Get the bounding box for the face\n","            box = detections[0, 0, 0, 3:7] * np.array([w, h, w, h])\n","            (startX, startY, endX, endY) = box.astype(\"int\")\n","            if startX > np.shape(img)[1] or startX < 0:\n","                startX = 0\n","            if startY > np.shape(img)[0] or startY < 0:\n","                startY = 0\n","            if endX > np.shape(img)[1] or endX < 0:\n","                endX = np.shape(img)[1]\n","            if endY > np.shape(img)[0] or endY < 0:\n","                endY = np.shape(img)[0]\n","\n","            faces = img[startY:endY, startX:endX]\n","\n","            #write cropped faces to separate folder\n","            faces = cv2.resize(faces, (300, 300)) #resize the images to the same size\n","            path = '/content/drive/MyDrive/ECE50024Challenge/train_faces'\n","            cv2.imwrite(os.path.join(path , images), faces)\n","            cv2.waitKey(0)\n","        else:\n","            startX = 0\n","            startY = 0\n","            endX = np.shape(img)[1]\n","            endY = np.shape(img)[0]\n","            faces = img[startY:endY, startX:endX]\n","\n","            #write cropped faces to separate folder\n","            faces = cv2.resize(faces, (300, 300)) #resize the images to the same size\n","            path = '/content/drive/MyDrive/ECE50024Challenge/train_faces'\n","            cv2.imwrite(os.path.join(path , images), faces)\n","            cv2.waitKey(0)"]},{"cell_type":"code","source":["#Model\n","input_shape = (64, 64, 3)\n","num_classes = 100\n","model = keras.Sequential([\n","  layers.Rescaling(1./255, input_shape=input_shape),\n","\n","  layers.Conv2D(32, (3, 3), activation='relu'),\n","  layers.MaxPooling2D(2, 2),\n","  layers.Conv2D(64, (3, 3), activation='relu'),\n","  layers.MaxPooling2D(2, 2),\n","  layers.Conv2D(64, (3, 3), activation='relu'),\n","  layers.MaxPooling2D(2, 2),\n","  layers.Flatten(),\n","  layers.Dense(1024, activation='relu'),\n","  layers.Dense(num_classes, activation='softmax')\n","\n","])\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","model.summary()"],"metadata":{"id":"4QyPpVovHyFz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712024973288,"user_tz":240,"elapsed":352,"user":{"displayName":"Nicole Kozel","userId":"13795370668639158691"}},"outputId":"7fc44d71-b41c-4a0c-9162-999f632a4d00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_30\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," rescaling_22 (Rescaling)    (None, 64, 64, 3)         0         \n","                                                                 \n"," conv2d_99 (Conv2D)          (None, 62, 62, 32)        896       \n","                                                                 \n"," max_pooling2d_99 (MaxPooli  (None, 31, 31, 32)        0         \n"," ng2D)                                                           \n","                                                                 \n"," conv2d_100 (Conv2D)         (None, 29, 29, 64)        18496     \n","                                                                 \n"," max_pooling2d_100 (MaxPool  (None, 14, 14, 64)        0         \n"," ing2D)                                                          \n","                                                                 \n"," conv2d_101 (Conv2D)         (None, 12, 12, 64)        36928     \n","                                                                 \n"," max_pooling2d_101 (MaxPool  (None, 6, 6, 64)          0         \n"," ing2D)                                                          \n","                                                                 \n"," flatten_26 (Flatten)        (None, 2304)              0         \n","                                                                 \n"," dense_52 (Dense)            (None, 1024)              2360320   \n","                                                                 \n"," dense_53 (Dense)            (None, 100)               102500    \n","                                                                 \n","=================================================================\n","Total params: 2519140 (9.61 MB)\n","Trainable params: 2519140 (9.61 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["#determine num of images cropped to faces\n","image_count = 69540\n","skipped = []\n","incl_img = 0\n","# Load the DNN Face Detector model\n","from cv2 import dnn\n","prototxt = '/content/drive/MyDrive/ECE50024Challenge/deploy.prototxt.txt'\n","caffemodel='/content/drive/MyDrive/ECE50024Challenge/res10_300x300_ssd_iter_140000.caffemodel'\n","face_detector =  cv2.dnn.readNetFromCaffe( prototxt, caffemodel)\n","\n","x_train = []\n","for k in range(image_count):\n","  if k < 10000:\n","    folder = '10000/'\n","  if k >= 10000 and k < 20000:\n","    folder = '20000/'\n","  if k >= 20000 and k < 30000:\n","    folder = '30000/'\n","  if k >= 30000 and k < 40000:\n","    folder = '40000/'\n","  if k >= 40000 and k < 50000:\n","    folder = '50000/'\n","  if k >= 50000 and k < 60000:\n","    folder = '60000/'\n","  if k >= 60000:\n","    folder = '69540/'\n","  images = folder+str(k)+'.jpg'\n","  img = cv2.resize(cv2.imread('/content/drive/MyDrive/ECE50024Challenge/train_faces/'+images), (64, 64))\n","\n","  #only include the faces it's confident in\n","  # Get the height and width of the input image\n","  (h, w) = img.shape[:2]\n","\n","  # Preprocess the image by resizing it and converting it to a blob\n","  blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n","\n","  # Feed the blob as input to the DNN Face Detector model\n","  face_detector.setInput(blob)\n","  detections = face_detector.forward()\n","\n","  # Loop over the detections and draw a rectangle around each face\n","  confidence = detections[0, 0, 0, 2]\n","\n","  # Filter out weak detections\n","  if confidence > 0.5:\n","    img = tf.convert_to_tensor(img, dtype=tf.float32)\n","    x_train.append(img)\n","    incl_img += 1\n","  else:\n","    skipped.append(k)\n","  print(k)"],"metadata":{"id":"edVN3PdZqDGx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get int values for the classes\n","with open('/content/drive/MyDrive/ECE50024Challenge/category.csv', mode ='r')as file:\n","  train_labels_num = csv.reader(file)\n","  k = 0\n","  c_num = np.zeros([num_classes,1])\n","  name_num = [] #Class name\n","  for lines in train_labels_num:\n","    if lines[0] != \"\":\n","        c_num[k] = lines[0]\n","        name_num.append(lines[1])\n","        k += 1\n","\n","# Get labels for the data\n","k = 0\n","c = np.zeros([incl_img,1])\n","with open('/content/drive/MyDrive/ECE50024Challenge/train.csv', mode ='r')as file:\n","  train_labels = csv.reader(file)\n","  for lines in train_labels:\n","    if lines[0] != \"\":\n","      if int(lines[0]) not in skipped:\n","        #if lines[1] == images:\n","        index = name_num.index(lines[2])\n","        c[k] = c_num[index]\n","        k += 1\n","#assemble training sets\n","y_train = keras.utils.to_categorical(c, num_classes)"],"metadata":{"id":"SOlTd-vZmdb1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(np.shape(y_train))\n","print(np.shape(x_train))\n","print(incl_img) #check that proper number of confident images are included"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xdrBXJgX6K5l","executionInfo":{"status":"ok","timestamp":1712020405419,"user_tz":240,"elapsed":1652,"user":{"displayName":"Nicole Kozel","userId":"13795370668639158691"}},"outputId":"ea4df049-d89d-4772-f4a0-9ac6f033affa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(66232, 100)\n","(66232, 64, 64, 3)\n","66232\n"]}]},{"cell_type":"code","source":["x_train = tf.stack(x_train, axis=0)"],"metadata":{"id":"F4M-b77JGCA5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#run model\n","batch_size = 32\n","epochs = 6\n","\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=True, validation_split=0.2)"],"metadata":{"id":"R4jBO-HmH335","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712025045492,"user_tz":240,"elapsed":68287,"user":{"displayName":"Nicole Kozel","userId":"13795370668639158691"}},"outputId":"9dfdda4f-7951-47f1-d78a-a18dd2b73e1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/6\n","1656/1656 [==============================] - 13s 7ms/step - loss: 3.8905 - accuracy: 0.1348 - val_loss: 3.3192 - val_accuracy: 0.2483\n","Epoch 2/6\n","1656/1656 [==============================] - 11s 6ms/step - loss: 2.8838 - accuracy: 0.3568 - val_loss: 2.7592 - val_accuracy: 0.3915\n","Epoch 3/6\n","1656/1656 [==============================] - 11s 6ms/step - loss: 2.2985 - accuracy: 0.4878 - val_loss: 2.4879 - val_accuracy: 0.4731\n","Epoch 4/6\n","1656/1656 [==============================] - 11s 6ms/step - loss: 1.8738 - accuracy: 0.5780 - val_loss: 2.3995 - val_accuracy: 0.5133\n","Epoch 5/6\n","1656/1656 [==============================] - 11s 6ms/step - loss: 1.5476 - accuracy: 0.6471 - val_loss: 2.3488 - val_accuracy: 0.5391\n","Epoch 6/6\n","1656/1656 [==============================] - 11s 6ms/step - loss: 1.2594 - accuracy: 0.7034 - val_loss: 2.4948 - val_accuracy: 0.5385\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x78b6e21e4580>"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["#Assemble test data\n","\n","# Load the DNN Face Detector model\n","from cv2 import dnn\n","prototxt = '/content/drive/MyDrive/ECE50024Challenge/deploy.prototxt.txt'\n","caffemodel='/content/drive/MyDrive/ECE50024Challenge/res10_300x300_ssd_iter_140000.caffemodel'\n","face_detector =  cv2.dnn.readNetFromCaffe( prototxt, caffemodel)\n","#face_detector = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\", \"res10_300x300_ssd_iter_140000.caffemodel\")\n","\n","# get the path/directory\n","folder_dir = \"/content/drive/MyDrive/ECE50024Challenge/test/\"\n","for images in os.listdir(folder_dir):\n","    # check if the image ends with jpg\n","    if (images.endswith(\".jpg\")):\n","        #Make images readable\n","        img=Image.open('/content/drive/MyDrive/ECE50024Challenge/test/'+images)\n","        imgCheck = cv2.imread('/content/drive/MyDrive/ECE50024Challenge/test/'+images)\n","        if img.mode != 'RGB' or imgCheck is None:\n","            img = img.convert(mode=\"RGB\", colors=24)\n","            img.save('/content/drive/MyDrive/ECE50024Challenge/test_readable/'+images)\n","            img = cv2.imread('/content/drive/MyDrive/ECE50024Challenge/test_readable/'+images)\n","        else:\n","            img = cv2.imread('/content/drive/MyDrive/ECE50024Challenge/test/'+images)\n","\n","        # Get the height and width of the input image\n","        (h, w) = img.shape[:2]\n","\n","        # Preprocess the image by resizing it and converting it to a blob\n","        blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n","\n","        # Feed the blob as input to the DNN Face Detector model\n","        face_detector.setInput(blob)\n","        detections = face_detector.forward()\n","\n","        # Loop over the detections and draw a rectangle around each face\n","        confidence = detections[0, 0, 0, 2]\n","\n","        # Filter out weak detections\n","        if confidence > 0.25:\n","            # Get the bounding box for the face\n","            box = detections[0, 0, 0, 3:7] * np.array([w, h, w, h])\n","            (startX, startY, endX, endY) = box.astype(\"int\")\n","            if startX > np.shape(img)[1] or startX < 0:\n","                startX = 0\n","            if startY > np.shape(img)[0] or startY < 0:\n","                startY = 0\n","            if endX > np.shape(img)[1] or endX < 0:\n","                endX = np.shape(img)[1]\n","            if endY > np.shape(img)[0] or endY < 0:\n","                endY = np.shape(img)[0]\n","\n","            faces = img[startY:endY, startX:endX]\n","\n","            #write cropped faces to separate folder\n","            faces = cv2.resize(faces, (64, 64)) #resize the images to the same size\n","            path = '/content/drive/MyDrive/ECE50024Challenge/test_faces'\n","            cv2.imwrite(os.path.join(path , images), faces)\n","            cv2.waitKey(0)\n","        else:\n","            print(images)\n","            startX = 0\n","            startY = 0\n","            endX = np.shape(img)[1]\n","            endY = np.shape(img)[0]\n","            faces = img[startY:endY, startX:endX]\n","\n","            #write cropped faces to separate folder\n","            faces = cv2.resize(faces, (64, 64)) #resize the images to the same size\n","            path = '/content/drive/MyDrive/ECE50024Challenge/test_faces'\n","            cv2.imwrite(os.path.join(path , images), faces)\n","            cv2.waitKey(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":716},"id":"woIVqGybM3UZ","executionInfo":{"status":"error","timestamp":1711732127289,"user_tz":240,"elapsed":966036,"user":{"displayName":"Nicole Kozel","userId":"13795370668639158691"}},"outputId":"8aa97365-0d09-4a11-a97b-f26a8df16da4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4237.jpg\n","1749.jpg\n","4631.jpg\n","1826.jpg\n","3604.jpg\n","545.jpg\n","343.jpg\n","4036.jpg\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["2523.jpg\n","2324.jpg\n","4757.jpg\n","47.jpg\n","3010.jpg\n","3819.jpg\n","1997.jpg\n","4385.jpg\n","4390.jpg\n","1362.jpg\n","609.jpg\n","1868.jpg\n","2780.jpg\n","286.jpg\n","133.jpg\n","858.jpg\n","1658.jpg\n","1499.jpg\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-47d62c381af7>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#resize the images to the same size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/ECE50024Challenge/test_faces'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["folder_dir = \"/content/drive/MyDrive/ECE50024Challenge/test_faces/\"\n","for images in os.listdir(folder_dir):\n","    faces = cv2.imread('/content/drive/MyDrive/ECE50024Challenge/test_faces/'+images)\n","    faces = cv2.resize(faces, (64, 64)) #resize the images to the same size\n","    path = '/content/drive/MyDrive/ECE50024Challenge/test_faces'\n","    cv2.imwrite(os.path.join(path , images), faces)\n","    cv2.waitKey(0)"],"metadata":{"id":"s4KDsw0VL7kn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#determine num of images cropped to faces\n","image_count = len(os.listdir('/content/drive/MyDrive/ECE50024Challenge/test_faces'))\n","print(image_count)\n","\n","#assemble testing sets\n","\n","y_test = keras.utils.to_categorical(c, num_classes)\n","\n","x_test = []\n","\n","for k in range(image_count):\n","  image = str(k)+'.jpg'\n","  img = cv2.imread('/content/drive/MyDrive/ECE50024Challenge/test_faces/'+image)\n","  x_test.append(img)\n","\n","x_test = tf.convert_to_tensor(x_test, dtype=tf.float32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MeDx5hnJO8IF","outputId":"5a9164fc-04cb-4166-9d31-fae027847044","executionInfo":{"status":"ok","timestamp":1712020743260,"user_tz":240,"elapsed":93054,"user":{"displayName":"Nicole Kozel","userId":"13795370668639158691"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4977\n"]}]},{"cell_type":"code","source":["#Get predicted labels\n","labels = model.predict(x_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PWBZ7cjiMbS6","executionInfo":{"status":"ok","timestamp":1712022446203,"user_tz":240,"elapsed":704,"user":{"displayName":"Nicole Kozel","userId":"13795370668639158691"}},"outputId":"bf3efcde-b41b-47b0-a7c0-f8f3351c7598"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["156/156 [==============================] - 1s 3ms/step\n"]}]},{"cell_type":"code","source":["pred = []\n","for k in range(image_count):\n","    classGuess = np.where(labels[k] == max(labels[k]))\n","    nameGuess = name_num[int(classGuess[0])]\n","    row = [str(k), nameGuess]\n","    pred.append(row)\n","with open('/content/drive/MyDrive/ECE50024Challenge/submission4.csv', 'w', newline='') as file:\n","    writer = csv.writer(file)\n","    field = [\"Id\", \"Category\"]\n","    writer.writerow(field)\n","    for k in range(image_count):\n","        writer.writerow(pred[k])"],"metadata":{"id":"80fz0I4dVmBd"},"execution_count":null,"outputs":[]}]}